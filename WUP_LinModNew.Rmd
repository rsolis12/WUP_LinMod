---
title: "linear model from Web"
author: Robert solis"
date: "7/10/23 "
output:
   html_document:
         toc: true
         toc_depth: 5
        
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read about the data from the website where it is staged.  Then form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

 


```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(rgl)
require(knitr)

```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  

```

## Model 1 SIM~ARMS


  


### scatterplot

```{r}
basicNN <- ggplot(data, aes(y = SIMS, x = ARM)) +
  geom_point() +
  labs(title = "SIMS and ARM") +
  theme(plot.title = element_text(hjust = 0.5))

basicNN
```

### Numerical results
```{r}
cor(SIMS~ARM,data=data)
```
The numerical results for SIMS~AmRs is .6860073 this means the relationship between the two is fair in strength. 

### Inferential  (Build model.1)
```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```
The residual standard error is 1.226, the R squared is 0.4706. The comparison between the two that we always look at are the adjusted R quared. As we put our data in the R squared goes up.

#### Predict at target point

```{r}
mydata <-data.frame(GRIP=88,ARM=104)
predict.lm(model.1, mydata, interval = "prediction")
```


The value that is predicted is 1.57 in change and the interval was a positive 4.02 on change.
#### scatterplot with model fit
  

```{r}
basicNN <- ggplot(data, aes(y = SIMS, x = ARM)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "SIMS ~ ARM") +
  theme(plot.title = element_text(hjust = 0.5))

basicNN

```



## Model 2 SIM~GRIP




### Now add in scatterplot
```{r}
mygrip <- ggplot(data, aes(y = SIMS, x = GRIP)) +
  geom_point() +
  labs(title = "SIMS and GRIP") +
  theme(plot.title = element_text(hjust = 0.5))

mygrip
```

### Numerical results 
```{r}
cor(SIMS~GRIP,data=data)
```
The numerical results for SIMS~Grip is .6398458. SIMS~ARm has a higher,


### Inferential  (Build model.2)
```{r}
model.2 <- lm(SIMS~GRIP,data=data)
summary.lm(model.2)
```  
The residual standard error 1.295 and the R squared is 0.4094 SIMS~ARM has a better standard error and a better R squared number then SIMS`GRIp

#### predict model.2 at target point
```{r}
predict.lm(model.2, mydata, interval = "prediction")
```
The interval goes from -3.38434 to positive 1.766475.

#### now add the model fit to our plot for model.2
```{r}
mygrip <- ggplot(data, aes(y = SIMS, x = GRIP)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "SIMS ~ GRIP") +
  theme(plot.title = element_text(hjust = 0.5))

mygrip

```  


## Model 3 SIM~ARM+GRIP
```{r}
mygrip <- ggplot(data, aes(y = SIMS, x = GRIP)) +
  geom_point() +
  labs(title = "SIMS and GRIP") +
  theme(plot.title = element_text(hjust = 0.5))

mygrip
```

### Numerical results (cor)
```{r}
cor(SIMS~ARM + GRIP,data=data)
```
The correlation lis larger than SIMS~GRIP. WITH All tree together they are larger than .732
  
### Inferential  (Build 2-dimentional model.3)
```{r}
model.3 <- lm(SIMS~ARM + GRIP,data=data)
summary.lm(model.3)
```  
This model has a residual error of 1.144 and a R squared of .5422, this model has a better residual error SIMS~GRIP and SIMS~ARM. The models SIMS = .37311 * ARM + 2.4470 * GRIP - 5.433871

#### predict model.3 at target point
```{r}
predict.lm(model.3, mydata, interval = "prediction")
```  
The interval  goes from negative 1.716184 to positive 2.915777

## Comparing nested models ANOVA Test


### Model.1 vs Model.3

```{r}
anova(model.1, model.3)
```
It provides a p- value of 00000499, which does not have any value.

```{r}
anova(model.2, model.3)
```
The p value is alot smalller then model.1, model.3 there is a big difference between the data models. model 3 is better than model 1 and model 3 is better then model 2. This is based on the p value shown.


### Model.1 vs Model.2
```{r}
anova(model.1, model.2)
```
We reduced the sum of squared errors between these two models, that does not show its P values.

## Informally compare Model.1 with model.2

